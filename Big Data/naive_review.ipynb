{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "naive_review.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "nteract": {
      "version": "0.11.2"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rUVgL1wNNajZ",
        "colab": {}
      },
      "source": [
        "# Install Java, Spark, and Findspark\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-us.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGEkWcyUrOjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"NaiveBayes\").getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qnI0zdY5NYCJ",
        "outputId": "1e72980e-52f3-4cbe-fe0f-a42118c03d25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "url =\"https://s3.amazonaws.com/dataviz-curriculum/day_2/yelp_reviews.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.csv(SparkFiles.get(\"yelp_reviews.csv\"), sep=\",\", header=True)\n",
        "\n",
        "# Show DataFrame\n",
        "df.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+--------------------+\n",
            "|   class|                text|\n",
            "+--------+--------------------+\n",
            "|positive|Wow... Loved this...|\n",
            "|negative|  Crust is not good.|\n",
            "|negative|Not tasty and the...|\n",
            "|positive|Stopped by during...|\n",
            "|positive|The selection on ...|\n",
            "|negative|Now I am getting ...|\n",
            "|negative|Honeslty it didn'...|\n",
            "|negative|The potatoes were...|\n",
            "|positive|The fries were gr...|\n",
            "|positive|      A great touch.|\n",
            "|positive|Service was very ...|\n",
            "|negative|  Would not go back.|\n",
            "|negative|The cashier had n...|\n",
            "|positive|I tried the Cape ...|\n",
            "|negative|I was disgusted b...|\n",
            "|negative|I was shocked bec...|\n",
            "|positive| Highly recommended.|\n",
            "|negative|Waitress was a li...|\n",
            "|negative|This place is not...|\n",
            "|negative|did not like at all.|\n",
            "+--------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4BbzYExyNYCR",
        "outputId": "fed6e577-df63-473b-caa5-e74a0d5a9bb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "from pyspark.sql.functions import length\n",
        "# Create a length column to be used as a future feature \n",
        "data_df = df.withColumn('length', length(df['text']))\n",
        "data_df.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+--------------------+------+\n",
            "|   class|                text|length|\n",
            "+--------+--------------------+------+\n",
            "|positive|Wow... Loved this...|    24|\n",
            "|negative|  Crust is not good.|    18|\n",
            "|negative|Not tasty and the...|    41|\n",
            "|positive|Stopped by during...|    87|\n",
            "|positive|The selection on ...|    59|\n",
            "|negative|Now I am getting ...|    46|\n",
            "|negative|Honeslty it didn'...|    37|\n",
            "|negative|The potatoes were...|   111|\n",
            "|positive|The fries were gr...|    25|\n",
            "|positive|      A great touch.|    14|\n",
            "|positive|Service was very ...|    24|\n",
            "|negative|  Would not go back.|    18|\n",
            "|negative|The cashier had n...|    99|\n",
            "|positive|I tried the Cape ...|    59|\n",
            "|negative|I was disgusted b...|    62|\n",
            "|negative|I was shocked bec...|    50|\n",
            "|positive| Highly recommended.|    19|\n",
            "|negative|Waitress was a li...|    38|\n",
            "|negative|This place is not...|    51|\n",
            "|negative|did not like at all.|    20|\n",
            "+--------+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "od7Qj0sxNYCW"
      },
      "source": [
        "### Feature Transformations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "59dwxefsNYCX",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
        "# Create all the features to the data set\n",
        "\n",
        "#we're making all of this but we're not calling them yet\n",
        "\n",
        "#indexer convers values to numbers so it will convert positive to one number and negative to one number\n",
        "pos_neg_to_num = StringIndexer(inputCol='class',outputCol='label')\n",
        "\n",
        "#make a tokenizer convert inputs into a numeric vectors\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"token_text\")\n",
        "\n",
        "#make stopwords remover\n",
        "stopremove = StopWordsRemover(inputCol='token_text',outputCol='tokens_without_stop_words')\n",
        "\n",
        "#convert the tokens without stop words\n",
        "hashingTF = HashingTF(inputCol=\"tokens_without_stop_words\", outputCol='hash_token')\n",
        "\n",
        "\n",
        "idf = IDF(inputCol='hash_token', outputCol='idf_token')\n",
        "\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vector\n",
        "\n",
        "# Create feature vectors which are the numbers the model will be learning from\n",
        "features = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E_YyUpR3NYCf",
        "colab": {}
      },
      "source": [
        "# Create a and run a data processing Pipeline, this will do one step at a time in order \n",
        "from pyspark.ml import Pipeline\n",
        "data_prep_pipeline = Pipeline(stages=[pos_neg_to_num, tokenizer, stopremove, hashingTF, idf,features])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qBViHQOaNYCj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "330818b2-9b04-4a0e-e48a-adcddcff9854"
      },
      "source": [
        "# Fit and transform the pipeline\n",
        "cleaner = data_prep_pipeline.fit(data_df)\n",
        "cleaned = cleaner.transform(data_df)\n",
        "cleaned.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+--------------------+------+-----+--------------------+-------------------------+--------------------+--------------------+--------------------+\n",
            "|   class|                text|length|label|          token_text|tokens_without_stop_words|          hash_token|           idf_token|            features|\n",
            "+--------+--------------------+------+-----+--------------------+-------------------------+--------------------+--------------------+--------------------+\n",
            "|positive|Wow... Loved this...|    24|  0.0|[wow..., loved, t...|     [wow..., loved, p...|(262144,[33933,69...|(262144,[33933,69...|(262145,[33933,69...|\n",
            "|negative|  Crust is not good.|    18|  1.0|[crust, is, not, ...|           [crust, good.]|(262144,[150903,1...|(262144,[150903,1...|(262145,[150903,1...|\n",
            "|negative|Not tasty and the...|    41|  1.0|[not, tasty, and,...|     [tasty, texture, ...|(262144,[63367,11...|(262144,[63367,11...|(262145,[63367,11...|\n",
            "|positive|Stopped by during...|    87|  0.0|[stopped, by, dur...|     [stopped, late, m...|(262144,[6286,272...|(262144,[6286,272...|(262145,[6286,272...|\n",
            "|positive|The selection on ...|    59|  0.0|[the, selection, ...|     [selection, menu,...|(262144,[6979,911...|(262144,[6979,911...|(262145,[6979,911...|\n",
            "|negative|Now I am getting ...|    46|  1.0|[now, i, am, gett...|     [getting, angry, ...|(262144,[24661,34...|(262144,[24661,34...|(262145,[24661,34...|\n",
            "|negative|Honeslty it didn'...|    37|  1.0|[honeslty, it, di...|     [honeslty, taste,...|(262144,[101702,2...|(262144,[101702,2...|(262145,[101702,2...|\n",
            "|negative|The potatoes were...|   111|  1.0|[the, potatoes, w...|     [potatoes, like, ...|(262144,[3645,855...|(262144,[3645,855...|(262145,[3645,855...|\n",
            "|positive|The fries were gr...|    25|  0.0|[the, fries, were...|     [fries, great, too.]|(262144,[53777,13...|(262144,[53777,13...|(262145,[53777,13...|\n",
            "|positive|      A great touch.|    14|  0.0|  [a, great, touch.]|          [great, touch.]|(262144,[138356,2...|(262144,[138356,2...|(262145,[138356,2...|\n",
            "|positive|Service was very ...|    24|  0.0|[service, was, ve...|       [service, prompt.]|(262144,[24113,20...|(262144,[24113,20...|(262145,[24113,20...|\n",
            "|negative|  Would not go back.|    18|  1.0|[would, not, go, ...|              [go, back.]|(262144,[172477,1...|(262144,[172477,1...|(262145,[172477,1...|\n",
            "|negative|The cashier had n...|    99|  1.0|[the, cashier, ha...|     [cashier, care, e...|(262144,[36200,40...|(262144,[36200,40...|(262145,[36200,40...|\n",
            "|positive|I tried the Cape ...|    59|  0.0|[i, tried, the, c...|     [tried, cape, cod...|(262144,[18098,83...|(262144,[18098,83...|(262145,[18098,83...|\n",
            "|negative|I was disgusted b...|    62|  1.0|[i, was, disguste...|     [disgusted, prett...|(262144,[89493,95...|(262144,[89493,95...|(262145,[89493,95...|\n",
            "|negative|I was shocked bec...|    50|  1.0|[i, was, shocked,...|     [shocked, signs, ...|(262144,[86431,10...|(262144,[86431,10...|(262145,[86431,10...|\n",
            "|positive| Highly recommended.|    19|  0.0|[highly, recommen...|     [highly, recommen...|(262144,[31704,21...|(262144,[31704,21...|(262145,[31704,21...|\n",
            "|negative|Waitress was a li...|    38|  1.0|[waitress, was, a...|     [waitress, little...|(262144,[27707,65...|(262144,[27707,65...|(262145,[27707,65...|\n",
            "|negative|This place is not...|    51|  1.0|[this, place, is,...|     [place, worth, ti...|(262144,[12329,61...|(262144,[12329,61...|(262145,[12329,61...|\n",
            "|negative|did not like at all.|    20|  1.0|[did, not, like, ...|             [like, all.]|(262144,[8287,208...|(262144,[8287,208...|(262145,[8287,208...|\n",
            "+--------+--------------------+------+-----+--------------------+-------------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yssO0_Q5NYCb",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kDODyxF7NYCn",
        "outputId": "7f112f71-9ea6-43a3-fb22-e9ce7c6f2a5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# Show label and resulting features\n",
        "use_for_model= cleaned.select(['label', 'features'])\n",
        "use_for_model.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|  0.0|(262145,[33933,69...|\n",
            "|  1.0|(262145,[150903,1...|\n",
            "|  1.0|(262145,[63367,11...|\n",
            "|  0.0|(262145,[6286,272...|\n",
            "|  0.0|(262145,[6979,911...|\n",
            "|  1.0|(262145,[24661,34...|\n",
            "|  1.0|(262145,[101702,2...|\n",
            "|  1.0|(262145,[3645,855...|\n",
            "|  0.0|(262145,[53777,13...|\n",
            "|  0.0|(262145,[138356,2...|\n",
            "|  0.0|(262145,[24113,20...|\n",
            "|  1.0|(262145,[172477,1...|\n",
            "|  1.0|(262145,[36200,40...|\n",
            "|  0.0|(262145,[18098,83...|\n",
            "|  1.0|(262145,[89493,95...|\n",
            "|  1.0|(262145,[86431,10...|\n",
            "|  0.0|(262145,[31704,21...|\n",
            "|  1.0|(262145,[27707,65...|\n",
            "|  1.0|(262145,[12329,61...|\n",
            "|  1.0|(262145,[8287,208...|\n",
            "+-----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WzfCQmrVNYCr",
        "colab": {}
      },
      "source": [
        "# impoting our model wich is naivebayes\n",
        "from pyspark.ml.classification import NaiveBayes\n",
        "# Break data down into a training set and a testing set we are giving 75% for training and 25% for testing\n",
        "training, testing = use_for_model.randomSplit([0.75, 0.25])\n",
        "\n",
        "# Create a Naive Bayes model and fit training data\n",
        "model = NaiveBayes()\n",
        "classifier = model.fit(training)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zeckHhg5NYCv",
        "outputId": "235fe446-2d22-4d07-9245-5b8e6ff83e58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Tranform the model with the testing data\n",
        "test_results = classifier.transform(testing)\n",
        "test_results.show(5)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------------------+--------------------+--------------------+----------+\n",
            "|label|            features|       rawPrediction|         probability|prediction|\n",
            "+-----+--------------------+--------------------+--------------------+----------+\n",
            "|  0.0|(262145,[14,31463...|[-443.91527844789...|[0.00950475889819...|       1.0|\n",
            "|  0.0|(262145,[14,32970...|[-335.62519857118...|[0.23060072505452...|       1.0|\n",
            "|  0.0|(262145,[14,56428...|[-465.06763583831...|[0.99999999999998...|       0.0|\n",
            "|  0.0|(262145,[14,89717...|[-392.79600374413...|[1.89944578980408...|       1.0|\n",
            "|  0.0|(262145,[78,5377,...|[-609.31341359553...|[0.9999997971447,...|       0.0|\n",
            "+-----+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OVFrWcHINYCz",
        "outputId": "c4f6597c-a3a6-47a3-8c20-782a2148b9c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Use the Class Evaluator for a cleaner description\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval.evaluate(test_results)\n",
        "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of model at predicting reviews was: 0.729222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bOpKc638NlCQ",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}